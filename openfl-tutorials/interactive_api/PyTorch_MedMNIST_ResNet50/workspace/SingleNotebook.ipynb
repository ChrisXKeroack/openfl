{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd5da0c-1ae1-43e6-8ad9-360c8974476c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73e205-d273-4b6c-878a-5ea958bfe267",
   "metadata": {},
   "source": [
    "### Preparations in colab:\n",
    "We need to clone the repository to run a federation because it contains director and envoy configs to start from.\n",
    "\n",
    "1. Clone the OpenFL repository\n",
    "2. Install OpenFL \n",
    "3. Go to the linreg workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fafe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For right now, install from source, later we would migrate to PyPI install\n",
    "# !pip install openfl==1.2.1\n",
    "# !git clone https://github.com/intel/openfl.git\n",
    "# !cd openfl && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2698f1da-fa69-4543-bb15-c7c0dcb776b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from time import sleep\n",
    "\n",
    "# os.chdir('./openfl/openfl-tutorials/interactive_api/PyTorch_MedMNIST_ResNet50/workspace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637381d-84d0-4132-92c3-bf1a1e9c7f7a",
   "metadata": {},
   "source": [
    "# MedMNIST3D with PyTorch and OpenFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a29c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: medmnist in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: torchvision==0.8.1 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (0.8.1)\n",
      "Requirement already satisfied: ACSConv in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (0.1.1)\n",
      "Requirement already satisfied: torch==1.7.0 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from torchvision==0.8.1) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from torchvision==0.8.1) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from torchvision==0.8.1) (1.22.3)\n",
      "Requirement already satisfied: future in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from torch==1.7.0->torchvision==0.8.1) (0.18.2)\n",
      "Requirement already satisfied: typing-extensions in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from torch==1.7.0->torchvision==0.8.1) (3.10.0.2)\n",
      "Requirement already satisfied: dataclasses in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\n",
      "Requirement already satisfied: fire in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from medmnist) (0.4.0)\n",
      "Requirement already satisfied: scikit-learn in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from medmnist) (1.0.2)\n",
      "Requirement already satisfied: tqdm in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from medmnist) (4.63.1)\n",
      "Requirement already satisfied: pandas in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from medmnist) (1.4.1)\n",
      "Requirement already satisfied: scikit-image in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from medmnist) (0.19.2)\n",
      "Requirement already satisfied: tensorboardx in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from ACSConv) (2.5)\n",
      "Requirement already satisfied: matplotlib in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from ACSConv) (3.5.1)\n",
      "Requirement already satisfied: scipy in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from ACSConv) (1.8.0)\n",
      "Requirement already satisfied: six in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from fire->medmnist) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from fire->medmnist) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from matplotlib->ACSConv) (4.31.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from matplotlib->ACSConv) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from matplotlib->ACSConv) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from matplotlib->ACSConv) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from matplotlib->ACSConv) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from matplotlib->ACSConv) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from pandas->medmnist) (2022.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from scikit-image->medmnist) (2.16.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from scikit-image->medmnist) (2022.3.25)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from scikit-image->medmnist) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from scikit-image->medmnist) (2.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from scikit-learn->medmnist) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from scikit-learn->medmnist) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages (from tensorboardx->ACSConv) (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist torchvision==0.8.1 ACSConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4973a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itrushkin/.virtualenvs/openfl_research/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ``converters`` are currently experimental. It may not support operations including (but not limited to) Functions in ``torch.nn.functional`` that involved data dimension\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from models import ResNet18, ResNet50\n",
    "\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "from utils import model_to_syncbn, Transform3D\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    print('==> Preparing data...')\n",
    "\n",
    "    train_transform = Transform3D(mul='random') if shape_transform else Transform3D()\n",
    "    eval_transform = Transform3D(mul='0.5') if shape_transform else Transform3D()\n",
    "     \n",
    "    train_dataset = DataClass(split='train', transform=train_transform, download=download, as_rgb=as_rgb)\n",
    "    train_dataset_at_eval = DataClass(split='train', transform=eval_transform, download=download, as_rgb=as_rgb)\n",
    "    val_dataset = DataClass(split='val', transform=eval_transform, download=download, as_rgb=as_rgb)\n",
    "    test_dataset = DataClass(split='test', transform=eval_transform, download=download, as_rgb=as_rgb)\n",
    "\n",
    "    \n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    train_loader_at_eval = data.DataLoader(dataset=train_dataset_at_eval,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    val_loader = data.DataLoader(dataset=val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    return (train_loader, train_loader_at_eval, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6892a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(gpu_ids):\n",
    "    str_ids = gpu_ids.split(',')\n",
    "    gpu_ids = []\n",
    "    for str_id in str_ids:\n",
    "        id = int(str_id)\n",
    "        if id >= 0:`\n",
    "            gpu_ids.append(id)\n",
    "    if len(gpu_ids) > 0:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_ids[0])\n",
    "\n",
    "    return torch.device('cuda:{}'.format(gpu_ids[0])) if gpu_ids else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_channels, num_classes, conv, device):\n",
    "print('==> Building model...')\n",
    "\n",
    "    model = ResNet50(in_channels=n_channels, num_classes=n_classes)\n",
    "\n",
    "    if conv=='ACSConv':\n",
    "        model = model_to_syncbn(ACSConverter(model))\n",
    "    if conv=='Conv2_5d':\n",
    "        model = model_to_syncbn(Conv2_5dConverter(model))\n",
    "    if conv=='Conv3d':\n",
    "        if pretrained_3d == 'i3d':\n",
    "            model = model_to_syncbn(Conv3dConverter(model, i3d_repeat_axis=-3))\n",
    "        else:\n",
    "            model = model_to_syncbn(Conv3dConverter(model, i3d_repeat_axis=None))\n",
    "    \n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ce1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, writer):\n",
    "    total_loss = []\n",
    "    global iteration\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        targets = torch.squeeze(targets, 1).long().to(device)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "        writer.add_scalar('train_loss_logs', loss.item(), iteration)\n",
    "        iteration += 1\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = sum(total_loss)/len(total_loss)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3d0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, evaluator, data_loader, criterion, device, run, save_folder=None):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = []\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_1loader):\n",
    "            outputs = model(inputs.to(device))\n",
    "        \n",
    "            targets = torch.squeeze(targets, 1).long().to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "            m = nn.Softmax(dim=1)\n",
    "            outputs = m(outputs).to(device)\n",
    "            targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "        auc, acc = evaluator.evaluate(y_score, save_folder, run)\n",
    "\n",
    "        test_loss = sum(total_loss) / len(total_loss)\n",
    "\n",
    "        return [test_loss, auc, acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79772e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    data_flag='organmnist3d',\n",
    "    output_root='./output', # output root, where to save models\n",
    "    num_epochs=100, # num of epochs of training, the script would only test model if set num_epochs to 0\n",
    "    gpu_ids='0',\n",
    "    batch_size=32,\n",
    "    conv='ACSConv', # choose converter from Conv2_5d, Conv3d, ACSConv\n",
    "    pretrained_3d='i3d',\n",
    "    download=False,\n",
    "    as_rgb=False, # to copy channels, tranform shape 1x28x28x28 to 3x28x28x28\n",
    "    shape_transform=False, # for shape dataset, whether multiply 0.5 at eval\n",
    "    model_path=None, # root of the pretrained model to test\n",
    "    run='model1' # to name a standard evaluation csv file, named as {flag}_{split}_[AUC]{auc:.3f}_[ACC]{acc:.3f}@{run}.csv\n",
    "):\n",
    "    lr = 0.001\n",
    "    gamma=0.1\n",
    "    milestones = [0.5 * num_epochs, 0.75 * num_epochs]\n",
    "\n",
    "    info = INFO[data_flag]\n",
    "    task = info['task']\n",
    "    n_channels = 3 if as_rgb else info['n_channels']\n",
    "    n_classes = len(info['label'])\n",
    "\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    \n",
    "    device = get_device(gpu_ids)\n",
    "        \n",
    "    output_root = os.path.join(output_root, data_flag, time.strftime(\"%y%m%d_%H%M%S\"))\n",
    "    if not os.path.exists(output_root):\n",
    "        os.makedirs(output_root)\n",
    "\n",
    "    model = build_model(n_channels, n_classes, conv, device)\n",
    "\n",
    "    train_evaluator = medmnist.Evaluator(data_flag, 'train')\n",
    "    val_evaluator = medmnist.Evaluator(data_flag, 'val')\n",
    "    test_evaluator = medmnist.Evaluator(data_flag, 'test')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if model_path is not None:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device)['net'], strict=True)\n",
    "        train_metrics = test(model, train_evaluator, train_loader_at_eval, criterion, device, run, output_root)\n",
    "        val_metrics = test(model, val_evaluator, val_loader, criterion, device, run, output_root)\n",
    "        test_metrics = test(model, test_evaluator, test_loader, criterion, device, run, output_root)\n",
    "\n",
    "        print('train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2]) + \\\n",
    "              'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2]) + \\\n",
    "              'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2]))\n",
    "\n",
    "    if num_epochs == 0:\n",
    "        return\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "    \n",
    "    logs = ['loss', 'auc', 'acc']\n",
    "    train_logs = ['train_'+log for log in logs]\n",
    "    val_logs = ['val_'+log for log in logs]\n",
    "    test_logs = ['test_'+log for log in logs]\n",
    "    log_dict = OrderedDict.fromkeys(train_logs+val_logs+test_logs, 0)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=os.path.join(output_root, 'Tensorboard_Results'))\n",
    "\n",
    "    best_auc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = model\n",
    "\n",
    "    global iteration\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in trange(num_epochs):\n",
    "        \n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device, writer)\n",
    "        \n",
    "        train_metrics = test(model, train_evaluator, train_loader_at_eval, criterion, device, run)\n",
    "        val_metrics = test(model, val_evaluator, val_loader, criterion, device, run)\n",
    "        test_metrics = test(model, test_evaluator, test_loader, criterion, device, run)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        for i, key in enumerate(train_logs):\n",
    "            log_dict[key] = train_metrics[i]\n",
    "        for i, key in enumerate(val_logs):\n",
    "            log_dict[key] = val_metrics[i]\n",
    "        for i, key in enumerate(test_logs):\n",
    "            log_dict[key] = test_metrics[i]\n",
    "\n",
    "        for key, value in log_dict.items():\n",
    "            writer.add_scalar(key, value, epoch)\n",
    "            \n",
    "        cur_auc = val_metrics[1]\n",
    "        if cur_auc > best_auc:\n",
    "            best_epoch = epoch\n",
    "            best_auc = cur_auc\n",
    "            best_model = model\n",
    "\n",
    "            print('cur_best_auc:', best_auc)\n",
    "            print('cur_best_epoch', best_epoch)\n",
    "\n",
    "    state = {\n",
    "        'net': model.state_dict(),\n",
    "    }\n",
    "\n",
    "    path = os.path.join(output_root, 'best_model.pth')\n",
    "    torch.save(state, path)\n",
    "\n",
    "    train_metrics = test(best_model, train_evaluator, train_loader_at_eval, criterion, device, run, output_root)\n",
    "    val_metrics = test(best_model, val_evaluator, val_loader, criterion, device, run, output_root)\n",
    "    test_metrics = test(best_model, test_evaluator, test_loader, criterion, device, run, output_root)\n",
    "\n",
    "    train_log = 'train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2])\n",
    "    val_log = 'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2])\n",
    "    test_log = 'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2])\n",
    "\n",
    "    log = '%s\\n' % (data_flag) + train_log + val_log + test_log + '\\n'\n",
    "    print(log)\n",
    "    \n",
    "    with open(os.path.join(output_root, '%s_log.txt' % (data_flag)), 'a') as f:\n",
    "        f.write(log)        \n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6efb314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data...\n",
      "Using downloaded and verified file: /home/itrushkin/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /home/itrushkin/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /home/itrushkin/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /home/itrushkin/.medmnist/organmnist3d.npz\n",
      "==> Building and training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                 | 1/100 [00:53<1:28:01, 53.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_best_auc: 0.9591829190181452\n",
      "cur_best_epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█                                                 | 2/100 [01:49<1:29:24, 54.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_best_auc: 0.9967041187198948\n",
      "cur_best_epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▌                                               | 5/100 [04:38<1:28:53, 56.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_best_auc: 0.9997406949993156\n",
      "cur_best_epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████▉                                           | 12/100 [11:13<1:22:46, 56.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_best_auc: 1.0\n",
      "cur_best_epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 100/100 [1:34:07<00:00, 56.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organmnist3d\n",
      "train  auc: 1.00000  acc: 1.00000\n",
      "val  auc: 1.00000  acc: 0.99379\n",
      "test  auc: 0.99686  acc: 0.93770\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(download=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ffdb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e26a5-9f4e-4011-a999-e428246aa8c1",
   "metadata": {},
   "source": [
    "# Now we run the same training on federated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83378ece-9cd5-4d40-a134-24cf68bdb79a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Start the Director service and several envoys with generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d105a0-04c4-4c26-81c7-a350e14393c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the main parameters for our Federation\n",
    "n_cols=10\n",
    "n_samples_per_col=10\n",
    "noise=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c3e78b-6e9d-4efc-9b30-3ddc413c0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from typing import Dict, List, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a2821-b657-4e12-90ac-33b7810c5ff4",
   "metadata": {},
   "source": [
    "### Start the Director service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e736d33f-5df2-4a2f-8210-f1feba9fd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "director_workspace_path = Path('../director/').absolute()\n",
    "director_config_file = director_workspace_path / 'director_config.yaml'\n",
    "director_logfile = director_workspace_path / 'director.log'\n",
    "if director_logfile.is_file(): director_logfile.unlink()\n",
    "\n",
    "os.environ['main_folder'] = str(cwd)\n",
    "os.environ['director_workspace_path'] = str(director_workspace_path)\n",
    "os.environ['director_logfile'] = str(director_logfile)\n",
    "os.environ['director_config_file'] = str(director_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb950328-c1e6-4062-8b36-b42486d60241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script /bin/bash --bg\n",
    "cd $director_workspace_path\n",
    "fx director start --disable-tls -c $director_config_file > $director_logfile &\n",
    "cd $main_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f0037-c87e-440d-b8df-8fe9211c34dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start Envoys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6deeee4-5dc8-433d-a4ea-c464c74b1b2b",
   "metadata": {},
   "source": [
    "#### First, we create several envoy config files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0e65a39-15f7-4cca-90bb-a2970b7be9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original envoy config file content\n",
    "with open(Path('../envoy/envoy_config.yaml'), \"r\") as stream:\n",
    "    orig_config = yaml.safe_load(stream)\n",
    "\n",
    "def generate_envoy_configs(config: Dict,\n",
    "                           save_path: Union[str, Path] = '../envoy/',\n",
    "                           n_cols: int = 10,\n",
    "                           n_samples_per_col: int = 10,\n",
    "                           noise: float = 0.15) -> List[Path]:\n",
    "\n",
    "    config['shard_descriptor']['params']['n_samples'] = n_samples_per_col\n",
    "    config['shard_descriptor']['params']['noise'] = noise\n",
    "    \n",
    "    config_paths = [(Path(save_path) / f'{i}_envoy_config.yaml').absolute()\n",
    "                for i in range(1, n_cols + 1)]\n",
    "\n",
    "    for i, path in enumerate(config_paths):\n",
    "        config['shard_descriptor']['params']['rank'] = i\n",
    "        with open(path, \"w\") as stream:\n",
    "            yaml.safe_dump(config, stream)\n",
    "            \n",
    "    return config_paths\n",
    "            \n",
    "def remove_configs(config_paths):\n",
    "    for path in config_paths:\n",
    "        path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90109c5b-c785-4af7-ace9-dcd913018dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = generate_envoy_configs(orig_config,\n",
    "                                      n_cols=n_cols,\n",
    "                                      n_samples_per_col=n_samples_per_col,\n",
    "                                      noise=noise)\n",
    "# remove_configs(config_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3078a-7beb-47c5-bcee-2de264ef3266",
   "metadata": {},
   "source": [
    "#### Now start Envoy processes in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843f698e-5582-4918-828c-cf095988da92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sleep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfx envoy start -n env_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --disable-tls \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--envoy-config-path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -dh localhost -dp 50049 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>env_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.log &\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(cwd)\n\u001b[0;32m---> 12\u001b[0m \u001b[43msleep\u001b[49m(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     14\u001b[0m start_envoys(config_paths)\n\u001b[1;32m     16\u001b[0m sleep(\u001b[38;5;241m25\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sleep' is not defined"
     ]
    }
   ],
   "source": [
    "# envoy_workspace_path = Path('../envoy/').absolute()\n",
    "def start_envoys(config_paths: List[Path]) -> None:\n",
    "    envoy_workspace_path = config_paths[0].parent\n",
    "    cwd = Path.cwd()\n",
    "    os.chdir(envoy_workspace_path)\n",
    "    for i, path in enumerate(config_paths):\n",
    "        os.system(f'fx envoy start -n env_{i + 1} --disable-tls '\n",
    "                  f'--envoy-config-path {path} -dh localhost -dp 50049 '\n",
    "                  f'>env_{i + 1}.log &')\n",
    "    os.chdir(cwd)\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "start_envoys(config_paths)\n",
    "\n",
    "sleep(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216f14c-78d8-444c-9144-ee8316d1487b",
   "metadata": {},
   "source": [
    "## 2. Connect to the Director service of out Federation as Data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3b764-cb86-4eec-ba8e-df119da7a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50049\n",
    "\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed370b-d0c0-46bc-8114-ea8255b2478b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data scientist may request a list of connected envoys\n",
    "shard_registry = federation.get_shard_registry()\n",
    "\n",
    "# WARNING!\n",
    "\n",
    "# Make sure shard registry contains all the envoys you started!\n",
    "# In other case try rereconnecting to the Director (the cell above).\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6401026-795f-491e-90cb-dd59b451df5f",
   "metadata": {},
   "source": [
    "### Now we will prepare an FL experimnet using OpenFL Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166c689-9dde-4500-b05c-5b1ddf968978",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb1a98-b44f-47ff-950d-5a40a1cca0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "\n",
    "class LinRegDataSet(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize DataLoader.\"\"\"\n",
    "        self.kwargs = kwargs\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        \"\"\"Return shard descriptor.\"\"\"\n",
    "        return self._shard_descriptor\n",
    "    \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self.train_set = shard_descriptor.get_dataset(\"train\")\n",
    "        self.val_set = shard_descriptor.get_dataset(\"val\")\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract.\"\"\"\n",
    "        return self.train_set\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract.\"\"\"\n",
    "        return self.val_set\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.val_set)\n",
    "    \n",
    "lin_reg_dataset = LinRegDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233e1ed-a2f2-456f-9417-f35a2c27b236",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a8530-6248-4060-a30a-45cdc79bc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'custom_adapter.CustomFrameworkAdapter'\n",
    "fed_model = LinRegLasso(1)\n",
    "MI = ModelInterface(model=fed_model, optimizer=None, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = LinRegLasso(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9da235-02a8-4e7a-9455-5fe2462aa317",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tasks\n",
    "Using an Optimizer does not make sense for this experiment. Yet it is a required part of a training task contract in the current version of OpenFL, so we just pass None.\n",
    "We need to employ a trick reporting metrics. OpenFL decides which model is the best based on an *increasing* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e101689-8a63-4562-98ff-09443b1ab9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "@TI.add_kwargs(**{'lr': 0.001,\n",
    "                   'wd': 0.0001,\n",
    "                   'epoches': 1})\n",
    "@TI.register_fl_task(model='my_model', data_loader='train_data', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(my_model, train_data, optimizer, device, lr, wd, epoches):\n",
    "    X, Y = train_data[:,:-1], train_data[:,-1]\n",
    "    my_model.fit(X, Y, epochs, lr, wd, silent=True)\n",
    "    return {'train_MSE': my_model.mse(X, Y),}\n",
    "\n",
    "@TI.register_fl_task(model='my_model', data_loader='val_data', device='device')     \n",
    "def validate(my_model, val_data, device):\n",
    "    X, Y = val_data[:,:-1], val_data[:,-1]        \n",
    "    return {'validation_MSE': my_model.mse(X, Y),}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4623e-6559-4d4c-b199-f9afe16c0bbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb357a88-7098-45b2-85f4-71fe2f2e0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'linear_regression_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20124a-949d-4218-abfd-aaf4d0758284",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=lin_reg_dataset,\n",
    "                    rounds_to_train=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909be2b-d23b-4356-b2af-10a212382d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This method not only prints messages recieved from the director, \n",
    "# but also saves logs in the tensorboard format (by default)\n",
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd479019-1579-42c4-a446-f7d0a12596df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optional: start tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6faaaea",
   "metadata": {},
   "source": [
    "Locally, start tensorboard in background and open localhost:6006 in your browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4b673-e6b1-4bbe-8294-d2b61a65d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script /bin/bash --bg\n",
    "tensorboard --host $(hostname --all-fqdns | awk '{print $1}') --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68867a02",
   "metadata": {},
   "source": [
    "In Google Colab you may use the inline extension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3684b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d27834-ec5b-4290-8c9d-4c3c5589a7e6",
   "metadata": {},
   "source": [
    "### 3. Retrieve the trained model from the Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad915ab3-0032-4a06-b2c0-00710585e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_model = fl_experiment.get_last_model()\n",
    "best_model = fl_experiment.get_best_model()\n",
    "print(best_model.weights)\n",
    "print(last_model.weights)\n",
    "print(f\"last model MSE: {last_model.mse(x,y)}\")\n",
    "print(f\"best model MSE: {best_model.mse(x,y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930789e-b7b5-415e-844d-14ccc3844482",
   "metadata": {},
   "source": [
    "## Lets see what does the unified dataset looks like\n",
    "And see how the trained model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e8a56-d2f1-4758-a5a1-6d6652e4355e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cols = n_cols\n",
    "n_samples = n_samples_per_col\n",
    "interval = 240\n",
    "x_start = 60\n",
    "noise = noise\n",
    "\n",
    "X = None\n",
    "\n",
    "for rank in range(n_cols):\n",
    "    np.random.seed(rank)  # Setting seed for reproducibility\n",
    "    x = np.random.rand(n_samples, 1) * interval + x_start\n",
    "    x *= np.pi / 180\n",
    "    X = x if X is None else np.vstack((X,x))\n",
    "    y = np.sin(x) + np.random.normal(0, noise, size=(n_samples, 1))\n",
    "    plt.plot(x,y,'+')\n",
    "    \n",
    "X.sort()    \n",
    "Y_hat = last_model.predict(X)\n",
    "plt.plot(X,Y_hat,'--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e365766-4ea6-40bc-96ae-a183274e8b8c",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d793be-6c20-4a22-bad7-c082c1ee76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop all services run\n",
    "!pkill fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b8eb3-4775-43d9-8f96-de84a089a54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_configs(config_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b28b29-48d3-4f21-bc69-40259b83f93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
