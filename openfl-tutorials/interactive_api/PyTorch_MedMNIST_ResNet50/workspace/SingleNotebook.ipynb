{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd5da0c-1ae1-43e6-8ad9-360c8974476c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73e205-d273-4b6c-878a-5ea958bfe267",
   "metadata": {},
   "source": [
    "### Preparations in colab:\n",
    "We need to clone the repository to run a federation because it contains director and envoy configs to start from.\n",
    "\n",
    "1. Clone the OpenFL repository\n",
    "2. Install OpenFL \n",
    "3. Go to the medmnist workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fafe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For right now, install from source, later we would migrate to PyPI install\n",
    "# !pip install openfl==1.2.1\n",
    "# !git clone https://github.com/intel/openfl.git\n",
    "# !cd openfl && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2698f1da-fa69-4543-bb15-c7c0dcb776b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from time import sleep\n",
    "\n",
    "# os.chdir('./openfl/openfl-tutorials/interactive_api/PyTorch_MedMNIST_ResNet50/workspace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637381d-84d0-4132-92c3-bf1a1e9c7f7a",
   "metadata": {},
   "source": [
    "# MedMNIST3D with PyTorch and OpenFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a29c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medmnist\n",
      "  Using cached medmnist-2.0.2-py3-none-any.whl (21 kB)\n",
      "Collecting torchvision==0.8.1\n",
      "  Using cached torchvision-0.8.1-cp38-cp38-manylinux1_x86_64.whl (12.8 MB)\n",
      "Collecting ACSConv\n",
      "  Using cached ACSConv-0.1.1-py3-none-any.whl\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading Pillow-9.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "     |████████████████████████████████| 4.3 MB 1.7 MB/s            \n",
      "\u001b[?25hCollecting torch==1.7.0\n",
      "  Using cached torch-1.7.0-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n",
      "Requirement already satisfied: numpy in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from torchvision==0.8.1) (1.22.3)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from torch==1.7.0->torchvision==0.8.1) (3.10.0.2)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.19.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "Requirement already satisfied: pandas in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from medmnist) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from medmnist) (1.0.2)\n",
      "Requirement already satisfied: tqdm in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from medmnist) (4.63.0)\n",
      "Collecting fire\n",
      "  Using cached fire-0.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from ACSConv) (1.8.0)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "Requirement already satisfied: tensorboardx in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from ACSConv) (2.5)\n",
      "Collecting termcolor\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from fire->medmnist) (1.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from matplotlib->ACSConv) (21.3)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.31.2-py3-none-any.whl (899 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from matplotlib->ACSConv) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from matplotlib->ACSConv) (3.0.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from pandas->medmnist) (2022.1)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Using cached PyWavelets-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "Collecting networkx>=2.2\n",
      "  Using cached networkx-2.7.1-py3-none-any.whl (2.0 MB)\n",
      "Collecting imageio>=2.4.1\n",
      "  Using cached imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Using cached tifffile-2022.3.25-py3-none-any.whl (179 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from scikit-learn->medmnist) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from scikit-learn->medmnist) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages (from tensorboardx->ACSConv) (3.19.4)\n",
      "Installing collected packages: pillow, future, dataclasses, torch, tifffile, termcolor, PyWavelets, networkx, kiwisolver, imageio, fonttools, cycler, torchvision, scikit-image, matplotlib, fire, medmnist, ACSConv\n",
      "Successfully installed ACSConv-0.1.1 PyWavelets-1.3.0 cycler-0.11.0 dataclasses-0.6 fire-0.4.0 fonttools-4.31.2 future-0.18.2 imageio-2.16.1 kiwisolver-1.4.2 matplotlib-3.5.1 medmnist-2.0.2 networkx-2.7.1 pillow-9.1.0 scikit-image-0.19.2 termcolor-1.1.0 tifffile-2022.3.25 torch-1.7.0 torchvision-0.8.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/itrushkin/.virtualenvs/director/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist torchvision==0.8.1 ACSConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4973a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ``converters`` are currently experimental. It may not support operations including (but not limited to) Functions in ``torch.nn.functional`` that involved data dimension\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from models import ResNet18, ResNet50\n",
    "\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "from utils import model_to_syncbn, Transform3D\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b86ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(DataClass, batch_size):\n",
    "    print('==> Preparing data...')\n",
    "    \n",
    "    \n",
    "    train_transform = Transform3D()\n",
    "    eval_transform = Transform3D()\n",
    "     \n",
    "    train_dataset = DataClass(split='train', transform=train_transform, download=True, as_rgb=False)\n",
    "    train_dataset_at_eval = DataClass(split='train', transform=eval_transform, download=True, as_rgb=False)\n",
    "    val_dataset = DataClass(split='val', transform=eval_transform, download=True, as_rgb=False)\n",
    "    test_dataset = DataClass(split='test', transform=eval_transform, download=True, as_rgb=False)\n",
    "\n",
    "    \n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    train_loader_at_eval = data.DataLoader(dataset=train_dataset_at_eval,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    val_loader = data.DataLoader(dataset=val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    return (train_loader, train_loader_at_eval, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6892a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(gpu_ids):\n",
    "    str_ids = gpu_ids.split(',')\n",
    "    gpu_ids = []\n",
    "    for str_id in str_ids:\n",
    "        id = int(str_id)\n",
    "        if id >= 0:\n",
    "            gpu_ids.append(id)\n",
    "    if len(gpu_ids) > 0:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_ids[0])\n",
    "\n",
    "    return torch.device('cuda:{}'.format(gpu_ids[0])) if gpu_ids else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c60daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_channels, num_classes, conv, device):\n",
    "    print('==> Building model...')\n",
    "\n",
    "    model = ResNet50(in_channels=n_channels, num_classes=num_classes)\n",
    "\n",
    "    if conv=='ACSConv':\n",
    "        model = model_to_syncbn(ACSConverter(model))\n",
    "    if conv=='Conv2_5d':\n",
    "        model = model_to_syncbn(Conv2_5dConverter(model))\n",
    "    if conv=='Conv3d':\n",
    "        if pretrained_3d == 'i3d':\n",
    "            model = model_to_syncbn(Conv3dConverter(model, i3d_repeat_axis=-3))\n",
    "        else:\n",
    "            model = model_to_syncbn(Conv3dConverter(model, i3d_repeat_axis=None))\n",
    "    \n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ce1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, writer):\n",
    "    total_loss = []\n",
    "    global iteration\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        targets = torch.squeeze(targets, 1).long().to(device)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "        writer.add_scalar('train_loss_logs', loss.item(), iteration)\n",
    "        iteration += 1\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = sum(total_loss)/len(total_loss)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a3d0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, evaluator, data_loader, criterion, device, run, save_folder=None):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = []\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            outputs = model(inputs.to(device))\n",
    "        \n",
    "            targets = torch.squeeze(targets, 1).long().to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "            m = nn.Softmax(dim=1)\n",
    "            outputs = m(outputs).to(device)\n",
    "            targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "        auc, acc = evaluator.evaluate(y_score, save_folder, run)\n",
    "\n",
    "        test_loss = sum(total_loss) / len(total_loss)\n",
    "\n",
    "        return [test_loss, auc, acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79772e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    data_flag='organmnist3d',\n",
    "    output_root='./output', # output root, where to save models\n",
    "    num_epochs=100, # num of epochs of training, the script would only test model if set num_epochs to 0\n",
    "    gpu_ids='0',\n",
    "    batch_size=32,\n",
    "    conv='ACSConv', # choose converter from Conv2_5d, Conv3d, ACSConv\n",
    "    pretrained_3d='i3d',\n",
    "    download=False,\n",
    "    as_rgb=False, # to copy channels, tranform shape 1x28x28x28 to 3x28x28x28\n",
    "    shape_transform=False, # for shape dataset, whether multiply 0.5 at eval\n",
    "    model_path=None, # root of the pretrained model to test\n",
    "    run='model1' # to name a standard evaluation csv file, named as {flag}_{split}_[AUC]{auc:.3f}_[ACC]{acc:.3f}@{run}.csv\n",
    "):\n",
    "    lr = 0.001\n",
    "    gamma=0.1\n",
    "    milestones = [0.5 * num_epochs, 0.75 * num_epochs]\n",
    "\n",
    "    info = INFO[data_flag]\n",
    "    task = info['task']\n",
    "    n_channels = 3 if as_rgb else info['n_channels']\n",
    "    n_classes = len(info['label'])\n",
    "\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    \n",
    "    (train_loader, train_loader_at_eval, val_loader, test_loader) = prepare_data(DataClass, batch_size)\n",
    "    \n",
    "    device = get_device(gpu_ids)\n",
    "        \n",
    "    output_root = os.path.join(output_root, data_flag, time.strftime(\"%y%m%d_%H%M%S\"))\n",
    "    if not os.path.exists(output_root):\n",
    "        os.makedirs(output_root)\n",
    "\n",
    "    model = build_model(n_channels, n_classes, conv, device)\n",
    "\n",
    "    train_evaluator = medmnist.Evaluator(data_flag, 'train')\n",
    "    val_evaluator = medmnist.Evaluator(data_flag, 'val')\n",
    "    test_evaluator = medmnist.Evaluator(data_flag, 'test')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if model_path is not None:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device)['net'], strict=True)\n",
    "        train_metrics = test(model, train_evaluator, train_loader_at_eval, criterion, device, run, output_root)\n",
    "        val_metrics = test(model, val_evaluator, val_loader, criterion, device, run, output_root)\n",
    "        test_metrics = test(model, test_evaluator, test_loader, criterion, device, run, output_root)\n",
    "\n",
    "        print('train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2]) + \\\n",
    "              'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2]) + \\\n",
    "              'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2]))\n",
    "\n",
    "    if num_epochs == 0:\n",
    "        return\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "    \n",
    "    logs = ['loss', 'auc', 'acc']\n",
    "    train_logs = ['train_'+log for log in logs]\n",
    "    val_logs = ['val_'+log for log in logs]\n",
    "    test_logs = ['test_'+log for log in logs]\n",
    "    log_dict = OrderedDict.fromkeys(train_logs+val_logs+test_logs, 0)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=os.path.join(output_root, 'Tensorboard_Results'))\n",
    "\n",
    "    best_auc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = model\n",
    "\n",
    "    global iteration\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in trange(num_epochs):\n",
    "        \n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device, writer)\n",
    "        \n",
    "        train_metrics = test(model, train_evaluator, train_loader_at_eval, criterion, device, run)\n",
    "        val_metrics = test(model, val_evaluator, val_loader, criterion, device, run)\n",
    "        test_metrics = test(model, test_evaluator, test_loader, criterion, device, run)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        for i, key in enumerate(train_logs):\n",
    "            log_dict[key] = train_metrics[i]\n",
    "        for i, key in enumerate(val_logs):\n",
    "            log_dict[key] = val_metrics[i]\n",
    "        for i, key in enumerate(test_logs):\n",
    "            log_dict[key] = test_metrics[i]\n",
    "\n",
    "        for key, value in log_dict.items():\n",
    "            writer.add_scalar(key, value, epoch)\n",
    "            \n",
    "        cur_auc = val_metrics[1]\n",
    "        if cur_auc > best_auc:\n",
    "            best_epoch = epoch\n",
    "            best_auc = cur_auc\n",
    "            best_model = model\n",
    "\n",
    "            print('cur_best_auc:', best_auc)\n",
    "            print('cur_best_epoch', best_epoch)\n",
    "\n",
    "    state = {\n",
    "        'net': model.state_dict(),\n",
    "    }\n",
    "\n",
    "    path = os.path.join(output_root, 'best_model.pth')\n",
    "    torch.save(state, path)\n",
    "\n",
    "    train_metrics = test(best_model, train_evaluator, train_loader_at_eval, criterion, device, run, output_root)\n",
    "    val_metrics = test(best_model, val_evaluator, val_loader, criterion, device, run, output_root)\n",
    "    test_metrics = test(best_model, test_evaluator, test_loader, criterion, device, run, output_root)\n",
    "\n",
    "    train_log = 'train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2])\n",
    "    val_log = 'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2])\n",
    "    test_log = 'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2])\n",
    "\n",
    "    log = '%s\\n' % (data_flag) + train_log + val_log + test_log + '\\n'\n",
    "    print(log)\n",
    "    \n",
    "    with open(os.path.join(output_root, '%s_log.txt' % (data_flag)), 'a') as f:\n",
    "        f.write(log)        \n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6efb314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data...\n",
      "Using downloaded and verified file: /home/itrushkin/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /home/itrushkin/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /home/itrushkin/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /home/itrushkin/.medmnist/organmnist3d.npz\n",
      "==> Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                             | 0/100 [00:37<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data_flag, output_root, num_epochs, gpu_ids, batch_size, conv, pretrained_3d, download, as_rgb, shape_transform, model_path, run)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(num_epochs):\n\u001b[1;32m     76\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, train_loader, criterion, optimizer, device, writer)\n\u001b[0;32m---> 78\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_evaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_at_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     val_metrics \u001b[38;5;241m=\u001b[39m test(model, val_evaluator, val_loader, criterion, device, run)\n\u001b[1;32m     80\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m test(model, test_evaluator, test_loader, criterion, device, run)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, evaluator, data_loader, criterion, device, run, save_folder)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[1;32m     10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m---> 12\u001b[0m     targets \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     14\u001b[0m     m \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_experiment(download=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e26a5-9f4e-4011-a999-e428246aa8c1",
   "metadata": {},
   "source": [
    "# Now we run the same training on federated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83378ece-9cd5-4d40-a134-24cf68bdb79a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Start the Director service and several envoys with generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d105a0-04c4-4c26-81c7-a350e14393c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the main parameters for our Federation\n",
    "n_cols=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c3e78b-6e9d-4efc-9b30-3ddc413c0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from typing import Dict, List, Union\n",
    "from models import ResNet18, ResNet50\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import model_to_syncbn\n",
    "from acsconv.converters import ACSConverter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a2821-b657-4e12-90ac-33b7810c5ff4",
   "metadata": {},
   "source": [
    "### Start the Director service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e736d33f-5df2-4a2f-8210-f1feba9fd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "director_workspace_path = Path('../director/').absolute()\n",
    "director_config_file = director_workspace_path / 'director_config.yaml'\n",
    "director_logfile = director_workspace_path / 'director.log'\n",
    "if director_logfile.is_file(): director_logfile.unlink()\n",
    "\n",
    "os.environ['main_folder'] = str(cwd)\n",
    "os.environ['director_workspace_path'] = str(director_workspace_path)\n",
    "os.environ['director_logfile'] = str(director_logfile)\n",
    "os.environ['director_config_file'] = str(director_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb950328-c1e6-4062-8b36-b42486d60241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script /bin/bash --bg\n",
    "cd $director_workspace_path\n",
    "fx director start --disable-tls -c $director_config_file > $director_logfile &\n",
    "cd $main_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f0037-c87e-440d-b8df-8fe9211c34dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start Envoys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6deeee4-5dc8-433d-a4ea-c464c74b1b2b",
   "metadata": {},
   "source": [
    "#### First, we create several envoy config files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e65a39-15f7-4cca-90bb-a2970b7be9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original envoy config file content\n",
    "with open(Path('../envoy/envoy_config.yaml'), \"r\") as stream:\n",
    "    orig_config = yaml.safe_load(stream)\n",
    "\n",
    "def generate_envoy_configs(config: Dict,\n",
    "                           save_path: Union[str, Path] = '../envoy/',\n",
    "                           n_cols: int = 10,) -> List[Path]:\n",
    "    \n",
    "    config_paths = [(Path(save_path) / f'{i}_envoy_config.yaml').absolute()\n",
    "                for i in range(1, n_cols + 1)]\n",
    "\n",
    "    for i, path in enumerate(config_paths):\n",
    "        config['params']['cuda_devices'] = [i%3]\n",
    "        config['shard_descriptor']['params']['rank'] = i\n",
    "        config['shard_descriptor']['params']['worldsize'] = n_cols\n",
    "        with open(path, \"w\") as stream:\n",
    "            yaml.safe_dump(config, stream)\n",
    "            \n",
    "    return config_paths\n",
    "            \n",
    "def remove_configs(config_paths):\n",
    "    for path in config_paths:\n",
    "        path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90109c5b-c785-4af7-ace9-dcd913018dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = generate_envoy_configs(orig_config,\n",
    "                                      n_cols=n_cols)\n",
    "# remove_configs(config_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3078a-7beb-47c5-bcee-2de264ef3266",
   "metadata": {},
   "source": [
    "#### Now start Envoy processes in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "843f698e-5582-4918-828c-cf095988da92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting env_1...\n",
      "Starting env_2...\n",
      "Starting env_3...\n",
      "Starting env_4...\n",
      "Starting env_5...\n",
      "Starting env_6...\n",
      "Starting env_7...\n"
     ]
    }
   ],
   "source": [
    "# envoy_workspace_path = Path('../envoy/').absolute()\n",
    "def start_envoys(config_paths: List[Path]) -> None:\n",
    "    envoy_workspace_path = config_paths[0].parent\n",
    "    cwd = Path.cwd()\n",
    "    os.chdir(envoy_workspace_path)\n",
    "    for i, path in enumerate(config_paths):\n",
    "        env_name = f'env_{i + 1}'\n",
    "        print(f'Starting {env_name}...')\n",
    "        os.system(f'fx envoy start -n {env_name} --disable-tls '\n",
    "                  f'--envoy-config-path {path} -dh localhost -dp 50049 '\n",
    "                  f'>env_{i + 1}.log &')\n",
    "    os.chdir(cwd)\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "start_envoys(config_paths)\n",
    "\n",
    "sleep(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216f14c-78d8-444c-9144-ee8316d1487b",
   "metadata": {},
   "source": [
    "## 2. Connect to the Director service of out Federation as Data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d3b764-cb86-4eec-ba8e-df119da7a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50049\n",
    "\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bed370b-d0c0-46bc-8114-ea8255b2478b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_2': {'shard_info': node_info {\n",
       "    name: \"env_2\"\n",
       "    cuda_devices {\n",
       "      index: 1\n",
       "    }\n",
       "  }\n",
       "  shard_description: \"Allowed dataset types are `train` and `val`\"\n",
       "  sample_shape: \"1\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-04-04 10:52:27',\n",
       "  'current_time': '2022-04-04 10:52:30',\n",
       "  'valid_duration': seconds: 10,\n",
       "  'experiment_name': 'ExperimentName Mock'},\n",
       " 'env_1': {'shard_info': node_info {\n",
       "    name: \"env_1\"\n",
       "    cuda_devices {\n",
       "    }\n",
       "  }\n",
       "  shard_description: \"Allowed dataset types are `train` and `val`\"\n",
       "  sample_shape: \"1\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-04-04 10:52:28',\n",
       "  'current_time': '2022-04-04 10:52:30',\n",
       "  'valid_duration': seconds: 10,\n",
       "  'experiment_name': 'ExperimentName Mock'},\n",
       " 'env_3': {'shard_info': node_info {\n",
       "    name: \"env_3\"\n",
       "    cuda_devices {\n",
       "      index: 2\n",
       "    }\n",
       "  }\n",
       "  shard_description: \"Allowed dataset types are `train` and `val`\"\n",
       "  sample_shape: \"1\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-04-04 10:52:28',\n",
       "  'current_time': '2022-04-04 10:52:30',\n",
       "  'valid_duration': seconds: 10,\n",
       "  'experiment_name': 'ExperimentName Mock'},\n",
       " 'env_4': {'shard_info': node_info {\n",
       "    name: \"env_4\"\n",
       "    cuda_devices {\n",
       "    }\n",
       "  }\n",
       "  shard_description: \"Allowed dataset types are `train` and `val`\"\n",
       "  sample_shape: \"1\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-04-04 10:52:28',\n",
       "  'current_time': '2022-04-04 10:52:30',\n",
       "  'valid_duration': seconds: 10,\n",
       "  'experiment_name': 'ExperimentName Mock'},\n",
       " 'env_5': {'shard_info': node_info {\n",
       "    name: \"env_5\"\n",
       "    cuda_devices {\n",
       "      index: 1\n",
       "    }\n",
       "  }\n",
       "  shard_description: \"Allowed dataset types are `train` and `val`\"\n",
       "  sample_shape: \"1\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-04-04 10:52:28',\n",
       "  'current_time': '2022-04-04 10:52:30',\n",
       "  'valid_duration': seconds: 10,\n",
       "  'experiment_name': 'ExperimentName Mock'},\n",
       " 'env_6': {'shard_info': node_info {\n",
       "    name: \"env_6\"\n",
       "    cuda_devices {\n",
       "      index: 2\n",
       "    }\n",
       "  }\n",
       "  shard_description: \"Allowed dataset types are `train` and `val`\"\n",
       "  sample_shape: \"1\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-04-04 10:52:28',\n",
       "  'current_time': '2022-04-04 10:52:30',\n",
       "  'valid_duration': seconds: 10,\n",
       "  'experiment_name': 'ExperimentName Mock'},\n",
       " 'env_7': {'shard_info': node_info {\n",
       "    name: \"env_7\"\n",
       "    cuda_devices {\n",
       "    }\n",
       "  }\n",
       "  shard_description: \"Allowed dataset types are `train` and `val`\"\n",
       "  sample_shape: \"1\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-04-04 10:52:28',\n",
       "  'current_time': '2022-04-04 10:52:30',\n",
       "  'valid_duration': seconds: 10,\n",
       "  'experiment_name': 'ExperimentName Mock'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data scientist may request a list of connected envoys\n",
    "shard_registry = federation.get_shard_registry()\n",
    "\n",
    "# WARNING!\n",
    "\n",
    "# Make sure shard registry contains all the envoys you started!\n",
    "# In other case try rereconnecting to the Director (the cell above).\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6401026-795f-491e-90cb-dd59b451df5f",
   "metadata": {},
   "source": [
    "### Now we will prepare an FL experimnet using OpenFL Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166c689-9dde-4500-b05c-5b1ddf968978",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55fb1a98-b44f-47ff-950d-5a40a1cca0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "\n",
    "class MedMnistDataSet(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize DataLoader.\"\"\"\n",
    "        self.kwargs = kwargs\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        \"\"\"Return shard descriptor.\"\"\"\n",
    "        return self._shard_descriptor\n",
    "    \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self.train_set = shard_descriptor.get_dataset(\"train\")\n",
    "        self.val_set = shard_descriptor.get_dataset(\"val\")\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract.\"\"\"\n",
    "        return DataLoader(self.train_set, batch_size=self.kwargs['train_bs'], shuffle=True)\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract.\"\"\"\n",
    "        return DataLoader(self.val_set, batch_size=self.kwargs['valid_bs'], shuffle=True)\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.val_set)\n",
    "    \n",
    "lin_reg_dataset = MedMnistDataSet(train_bs=4, valid_bs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233e1ed-a2f2-456f-9417-f35a2c27b236",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "885a8530-6248-4060-a30a-45cdc79bc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "fed_model = ResNet50(in_channels=1, num_classes=11)\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(fed_model.parameters(), lr=lr)\n",
    "MI = ModelInterface(model=fed_model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = ResNet50(in_channels=1, num_classes=11)\n",
    "fed_model = model_to_syncbn(ACSConverter(fed_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9da235-02a8-4e7a-9455-5fe2462aa317",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tasks\n",
    "Using an Optimizer does not make sense for this experiment. Yet it is a required part of a training task contract in the current version of OpenFL, so we just pass None.\n",
    "We need to employ a trick reporting metrics. OpenFL decides which model is the best based on an *increasing* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e101689-8a63-4562-98ff-09443b1ab9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "@TI.register_fl_task(model='my_model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(my_model, train_loader, optimizer, device, criterion=nn.CrossEntropyLoss()):\n",
    "    total_loss = []\n",
    "    my_model = my_model.to(device)\n",
    "    my_model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = my_model(torch.tensor(inputs).to(device))\n",
    "\n",
    "        targets = torch.squeeze(targets, 1).long().to(device)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = sum(total_loss)/len(total_loss)\n",
    "    return {'loss': epoch_loss}\n",
    "\n",
    "@TI.register_fl_task(model='my_model', data_loader='val_loader', device='device')     \n",
    "def validate(my_model, val_loader, device, criterion=nn.CrossEntropyLoss()):\n",
    "    def get_auc(y_true, y_score):\n",
    "        auc = 0\n",
    "        for i in range(y_score.shape[1]):\n",
    "            y_true_binary = (y_true == i).astype(float)\n",
    "            y_score_binary = y_score[:, i]\n",
    "            auc += roc_auc_score(y_true_binary, y_score_binary)\n",
    "        ret = auc / y_score.shape[1]\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    def get_acc(y_true, y_score):\n",
    "        ret = accuracy_score(y_true, np.argmax(y_score, axis=-1))\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    my_model = my_model.to(device)\n",
    "    my_model.eval()\n",
    "\n",
    "    total_loss = []\n",
    "    y_true = []\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            outputs = my_model(inputs.to(device))\n",
    "            y_true += targets\n",
    "            targets = torch.squeeze(targets, 1).long().to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "            m = nn.Softmax(dim=1)\n",
    "            outputs = m(outputs).to(device)\n",
    "            targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "        \n",
    "        y_true = np.stack(y_true)\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "        try:\n",
    "            auc = get_auc(y_true, y_score)\n",
    "        except:\n",
    "            print(f'{y_true=}')\n",
    "            raise\n",
    "        acc = get_acc(y_true, y_score)\n",
    "\n",
    "        val_loss = sum(total_loss) / len(total_loss)\n",
    "\n",
    "        return {'val_loss':val_loss, 'auc':auc, 'acc':acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4623e-6559-4d4c-b199-f9afe16c0bbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb357a88-7098-45b2-85f4-71fe2f2e0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'medmnist_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db20124a-949d-4218-abfd-aaf4d0758284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[10:52:30] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/itrushkin/repos/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bc0e18460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/itrushkin/repos/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bc0e182e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itrushkin/.virtualenvs/director/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[10:52:41] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/itrushkin/repos/openfl/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe641ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">563bcaee91ef5b048cb995cb470eadd4b3c734a18f4c3ea4a49d02640a63d23b1835daf9ee9c5d8aca464e464b03eebd</span>                 <a href=\"file:///home/itrushkin/repos/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bc0de1a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">563bcaee91ef5b048cb995cb470eadd4b3c734a18f4c3ea4a49d02640a63d23b1835daf9ee9c5d8aca464e464b03eebd</span>                 <a href=\"file:///home/itrushkin/repos/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6f2e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/itrushkin/repos/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6f2dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/itrushkin/repos/openfl/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6b7af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/itrushkin/repos/openfl/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6b7b80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/itrushkin/repos/openfl/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6b7ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/itrushkin/repos/openfl/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6b7b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[10:52:57] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/itrushkin/repos/openfl/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:228</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6b7520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=lin_reg_dataset,\n",
    "                    rounds_to_train=10,\n",
    "                    device_assignment_policy='CUDA_PREFERRED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4909be2b-d23b-4356-b2af-10a212382d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/itrushkin/.virtualenvs/director/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/itrushkin/.virtualenvs/director/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/itrushkin/.virtualenvs/director/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/itrushkin/.virtualenvs/director/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/itrushkin/.virtualenvs/director/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/itrushkin/.virtualenvs/director/bin/python -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/itrushkin/.virtualenvs/director/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# This method not only prints messages recieved from the director, \n",
    "# but also saves logs in the tensorboard format (by default)\n",
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd479019-1579-42c4-a446-f7d0a12596df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optional: start tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6faaaea",
   "metadata": {},
   "source": [
    "Locally, start tensorboard in background and open localhost:6006 in your browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5f4b673-e6b1-4bbe-8294-d2b61a65d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script /bin/bash --bg\n",
    "tensorboard --host $(hostname --all-fqdns | awk '{print $1}') --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68867a02",
   "metadata": {},
   "source": [
    "In Google Colab you may use the inline extension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3684b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 7900), started 2 days, 16:51:46 ago. (Use '!kill 7900' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a8770c240121bfe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a8770c240121bfe\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d27834-ec5b-4290-8c9d-4c3c5589a7e6",
   "metadata": {},
   "source": [
    "### 3. Retrieve the trained model from the Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad915ab3-0032-4a06-b2c0-00710585e24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[10:53:16] </span><span style=\"color: #800000\">WARNING</span>  No tensors received from director                                                                                          <a href=\"file:///home/itrushkin/repos/openfl/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:104</span>\n",
       "                    Possible reasons:                                                                                                                           \n",
       "                            <span style=\"color: #000080; font-weight: bold\">1</span>. Aggregated model is not ready                                                                                                    \n",
       "                            <span style=\"color: #000080; font-weight: bold\">2</span>. Experiment data removed from director                                                                                            \n",
       "                    Return initial model                                                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6b7d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  No tensors received from director                                                                                          <a href=\"file:///home/itrushkin/repos/openfl/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:104</span>\n",
       "                    Possible reasons:                                                                                                                           \n",
       "                            <span style=\"color: #000080; font-weight: bold\">1</span>. Aggregated model is not ready                                                                                                    \n",
       "                            <span style=\"color: #000080; font-weight: bold\">2</span>. Experiment data removed from director                                                                                            \n",
       "                    Return initial model                                                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2bbe6455b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'ResNet' object has no attribute 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m last_model \u001b[38;5;241m=\u001b[39m fl_experiment\u001b[38;5;241m.\u001b[39mget_last_model()\n\u001b[1;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m fl_experiment\u001b[38;5;241m.\u001b[39mget_best_model()\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(last_model\u001b[38;5;241m.\u001b[39mweights)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast model MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_model\u001b[38;5;241m.\u001b[39mmse(x,y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/director/lib/python3.8/site-packages/torch/nn/modules/module.py:778\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m    777\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ModuleAttributeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'ResNet' object has no attribute 'weights'"
     ]
    }
   ],
   "source": [
    "last_model = fl_experiment.get_last_model()\n",
    "best_model = fl_experiment.get_best_model()\n",
    "print(best_model.weights)\n",
    "print(last_model.weights)\n",
    "print(f\"last model MSE: {last_model.mse(x,y)}\")\n",
    "print(f\"best model MSE: {best_model.mse(x,y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e365766-4ea6-40bc-96ae-a183274e8b8c",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d793be-6c20-4a22-bad7-c082c1ee76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop all services run\n",
    "!pkill fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b8eb3-4775-43d9-8f96-de84a089a54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_configs(config_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b28b29-48d3-4f21-bc69-40259b83f93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
